# 小灰漫画算法

# 一、算法概述

## 1. 算法
1. **时间复杂度和空间复杂度**
2. 算法应用的领域：运算、查找、排序、最优决策。

### 2. 数据结构
1. 数据结构的组成：线性结构、树、图
2. 线性结构，包括数组和链表以及由它们衍
生出来的栈、队列、哈希表。
3. 数，二叉树及其衍生出的二叉堆之类的数据结构

### 3. 时间复杂度(大O表示法)
1. 推导出时间复杂度的原则:
- 如果运行时间是常数量级，则用常数1表示，O(1)
- **只保留时间函数中的最高阶项**
- 如果最高阶项存在，则省去最高阶项前面的系数
2. **当n的取值足够大时，时间复杂度为：O(1)<O(logn)<O(n)<O(n ^2)**
3. 递归算法的空间复杂度和递归深度成正比，递归的深度是n，那么空间复杂度就是O(n)。

# 二、基础数据结构

## 1. 数组
1. **数组，array**，有限个**相同类型的变量**所组成的**有序集合**，数组中每一个变量被称为元素。
2. 其**在内存中顺序存储**。

#### 1.1 数组基本操作-读取元素 O(1)
1. **根据数组下标读取数组元素**，下标必须在数组len范围内，否则会出现**数组越界**。
2. 读取元素：array[3],时间复杂度O(1)
2. 这种根据下标读取元素的方式叫作**随机读取**。

#### 1.2 更新元素 O(1)
1. 元素重新赋值，array[5] = 10,时间复杂度O(1)

#### 1.3 插入元素 O(n)
1. 数组的实际元素数量有可能小于数组的长度。
2. 插入数组元素的操作存在三种情况
- 尾部插入
- 中间插入
- 超范围插入
3. **数组的扩容**，数组的长度在创建时就已经确定了，当已经填满了元素时，涉及数组扩容：**创建一个新数组，长度是旧数组的两倍，把旧数组中的数据统统复制过去**，就实现数组的扩容了。

#### 1.4 删除元素 O(n)
1. 数组的删除操作与插入操作过程相反，如果删除的元素位于数组中间，其后的元素都需向前挪动一位。

#### 1.5 优缺点
1. 数组有非常高效的随机访问能力，给出下标，O(1)就可以找到对应元素，有一种高效查找元素的算法:二分查找，就是利用了数组的这个优势。
2. 劣势:插入和删除元素慢。
3. **数组适合读操作多，写操作少的场景**，与链表相反。

## 2. 链表
1. 链表(linked list)是一种在物理上非连续、非顺序的数据结构，由若干节点(node)所组成。
2. 链表在内存中的存储方式是随机存储，数组则是顺序存储。
3. 链表采用**见缝插针**的方式，链表的**每一个节点分布在内存的不同位置，依靠next指针关联起来**，这样可以灵活有效的利用零散的碎片空间。

#### 2.1 基本操作-查找节点O(n)
1. 从头节点向后逐个查找，O(n)

#### 2.2 更新节点O(1)

#### 2.3 插入节点、删除节点O(1)
- 尾部插入
- 头部插入
- 中间插入
1. 只要内存空间允许，能够插入链表的元素是无穷尽的，不需要像数组那样考虑扩容的问题。
2. 如果不考虑插入、删除之前查找元素的过程，只考虑纯粹的插入和删除操作，时间复杂度都是O(1)

#### 2.4 数组和链表的性能比较

对比 | 查找 | 更新 | 插入 | 删除
---|---|---|---|---
数组 | O(1) | O(1) | O(n) | O(n)  
链表 | O(n) | O(1) | O(1) | O(1)
1. **数组的优势在于快速定位元素，适用于读操作多、写操作少**
2. **链表在于灵活的进行插入和删除操作，如果需要在尾部频繁插入、删除元素，用
链表更合适一些。**

## 3. 栈和队列

#### 3.1 物理结构和逻辑结构
1. **物理结构就是在内存中实实在在存在的数据结构，如数组和链表。**
2. **逻辑结构是抽象的概念，他依赖于物理结构而存在。**
3. 物理结构：数组和链表
4. 逻辑结构中分：线性结构:顺序表、栈、队列；非线性结构:树、图。
5. 栈和队列既能用数组实现，也能用链表实现

#### 3.2 栈(stack)
1. 栈，一种线性数据结构，元素遵循**先进后出**，最早进入的元素存放的位置叫栈底，最后进入的元素存放的位置叫栈顶。
2. 入栈操作(push)
3. 出栈操作(pop)
4. 用数组或者链表实现的栈，入栈和出栈只影响最后一个元素，其**时间复杂度都是O(1)**

#### 3.3 队列(queue)
1. 队列，一种线性数据结构，元素遵循先进先出。
2. 队列操作：**入队和出队，时间复杂度均为O(1)**
3. 入队:在队尾位置追加元素，成为新的队尾
4. 出队:把对头元素移出。
5. 元素不断出队时，用**循环队列**的方式来维持队列容量的恒定，在物理存储上，队尾的位置也可以在队头之前。当再有元素入队时，将其放入数组的首位，队尾指针继续后移即可。
6. **队尾指针指向的位置永远空出1位，所以队列最大容量比数组长度小1**

#### 3.4 栈和队列的应用

##### 1. 栈的应用
1. 栈的输出顺序和输入顺序相反，所以栈通常用于对“**历史”的回溯**，也就是逆流而上追溯“历史”。
2. 实现**递归的逻辑**，就可以用栈来代替
3. 栈的一个应用场景是**面包屑导航**

##### 2. 队列的应用
1. 按照"历史"顺序，把历史重演一遍。
2. 例如在**多线程中**，**争夺公平锁的等待队列**，就是按照访问顺序来决定线程在队列中的次序的。

##### 3. 双端队列(deque)
1. 双端队列，综合了栈和队列的优点，既可以先入先出，也可以先入后出。从队头一端可以入队或出队，从队尾一端也可以入队或出队。

##### 4. 优先队列
1. **优先队列**，他遵循的不是先进先出，而是**谁的优先级高谁先出列。**
2. 优先队列不属于线性数据结构的范畴了，基于**二叉堆**来实现的

## 4. 散列表

#### 4.1 概述
1. **散列表，也叫哈希表**(hash table)，这种数据结构提供了键值的**映射关系**，只要给出一个Key,就可以高效的找到他所匹配的Value,时间复杂度O(1)。
2. 由于随机读取快速，查询效率最高，**散列表在本质上也是一个数组**。所以我们需要一个“中转站”，通过某
种方式，**把Key和数组下标进行转换**。这个中转站就叫作**哈希函数**。

#### 4.2 哈希函数
1. 在面向对象的语言中，每一个对象都有属于自己的
哈希值(hashcode)
1. **通过哈希函数，把字符串或其他类型的Key，转化成数组的下标index。**
2. index = HashCode (Key) % Array.length

#### 4.3 读写操作

##### 1. 写操作put
1. 写操作(put),在散列表中插入新的键值对。通过哈希函数，把key转化成数组下标，设上对应的元素value.
2. **哈希冲突**，即不同的Key通过哈希函数获得的下标有可能是相同的，且该位置已经有元素占用。**解决哈希冲突主要有两种：开放寻址法和链表法。**
3. **开放寻址法**:当一个Key通过哈希函数获得对应的数组下标已被占用时，**寻找下一空挡位置**，下标向后移动一位，看看位置是否被占用，直到有空位置，就可将其存进去
4. **链表法**：HashMap数组的每一个元素不仅是一个Entry对象，**还是一个链表的头节点**。每一个Entry对象通过next指针指向他的下一个Entry节点，**当新来的映射冲突时，只需插入到对应的链表中即可**。

##### 2. 读操作get
1. 通过Key在散列表中找到其所对应的值。
2. 通过哈希函数，把Key转化成数组下标2，找到数组下标2对应的元素，如果这个元素的key对应，就是他了。
3. 不对应继续往下找，**由于数组的每个元素都与一个链表对应，我们可以顺着链表慢慢往下找**，看看能否找到与Key相匹配的节点

##### 3. 扩容resize
1. 既然散列表是基于数组实现的，那么也涉及扩容的问题。
2. 当经过多次元素插入，散列表到达一定饱和度时，Key映射位置发生冲突的概率会逐渐提高。这样一来，大量元素拥挤在相同的数组下标位置，形成很长的链表，对后续插入及查询操作的性能都有很大影响。
3. 这时散列表就需要扩展他的长度，即扩容。**散列表扩容**：
- 创建一个长度是原数组2倍的新Entry空数组。
- 重新hash,遍历原Entry数组，把所有元素重新hash到新数组中。因为长度扩大以后，Hash的规则也随之改变
4. 经过扩容，原本拥挤的散列表重新变得稀疏，原有的Entry也重新得到了尽可能均匀的分配
5. **散列表可以说是数组和链表的结合**。

## 5. 小节

### 5.1 数组、链表、栈、队列、散列表
1. 数组是由有限个相同类型的变量所组成的有序集合，它的物理存
储方式是顺序存储，访问方式是随机访问。利用下标查找数组元素的
时间复杂度是O(1)，中间插入、删除数组元素的时间复杂度是O(n)。
2. 链表是一种链式数据结构，由若干节点组成，每个节点包含指向
下一节点的指针。链表的物理存储方式是随机存储，访问方式是顺序访问。查找链表节点的时间复杂度是O(n)，中间插入、删除节点的时间复杂度是O(1)。
3. 栈是一种线性逻辑结构，可以用数组实现，也可以用链表实现。栈包含入栈和出栈操作，遵循先入后出的原则（FILO）
4. 队列也是一种线性逻辑结构，可以用数组实现，也可以用链表实现。队列包含入队和出队操作，遵循先入先出的原则（FIFO）
5. 散列表也叫哈希表，是存储Key-Value映射的集合。对于某一个Key，散列表可以在接近O(1)的时间内进行读写操作。散列表通过哈希函数实现Key和数组下标的转换，通过开放寻址法和链表法来解决哈希冲突。

# 三、树

## 1. 树和二叉树

### 1.1 树
1. 实际场景中，许多逻辑关系并不是简单的线性关系，存在着一对多，多对多的场景，**树和图就是典型的非线性数据结构**。
2. 树(tree)是n(n>=0)个节点的有限集。当n=0时，称为空树，在任意一个非空树，有如下特点：
- 有且仅有一个节点的称为根的节点
- 当n>1时，其余节点可分为m(m>0)个互不相交的有限集，每一个集合本身又是一个树，并称为根的子树。
3. 根节点、叶子节点(旗下没有子节点的节点)、子树。
4. 树的最大层级数，被称为树的高度或深度

### 1.2 二叉树

##### 1. 二叉树、满二叉树、完全二叉树
1. **二叉树**，是**树的每个节点最多有2个孩子节点**。二叉树的两个孩子节点，左孩子、右孩子
3. 两个特殊的二叉树:**满二叉树、完全二叉树**
4. **满二叉树:一个二叉树的所有非叶子节点都存在左右孩子，并且所有叶子节点都在同一层级上。简单地说，满二叉树的每一个分支都是满的。**
5. **完全二叉树**:对一个有n个节点的二叉树，按层级顺序编号，则所有节点的编号为从1到n。如果这个树所有节点和同样深度的满二叉树的编号为从1到n的节点位置相同，则这个二叉树为完全二叉树。
6. 二叉树编号从1到12的12个节点，和前面满二叉树编
号从1到12的节点位置完全对应。因此这个树是完全二叉树。
7. 完全二叉树的条件没有满二叉树那么苛刻：满二叉树要求所有分支都是满的；而**完全二叉树只需保证最后一个节点之前的节点都齐全即可**。

##### 2. 二叉树的存储形式
1. 数据结构可以划分为物理结构和逻辑结构。二叉树属于逻辑结构，它可以通过多种物理结构来表达。
2. **通过链式存储结构**，二叉树的每个节点包含3部分：
- 存储数据的data变量
- 指向左孩子的left指针
- 指向右孩子的right指针
3. **通过数组存储**:使用数组存储时，会按照层级顺序把二叉树的节点放到数组中对应的位置上。如果某一个节点的左孩子或右孩子空缺，则数组的相应位置也空出来。
4. **更方便地在数组中定位二叉树的孩子节点和父节点**。假设一个父节点的下标是parent，那么它的左孩子节点下标就是2×parent + 1；右孩子节点下标就是2×parent + 2
5. 对于一个稀疏的二叉树来说，用数组表示法是非常浪费空间的

### 1.3 二叉树的应用
1. 二叉树最主要的应用还在于进行**查找**操作和**维持相对顺序**这两个方面

##### 1. 查找
1. 二叉树的树形结构使其很适合扮演**索引**的角色。
2. **二叉查找树**(binary search tree)也叫**二叉排序树**的条件:
- 如果左子树不为空，则左子树上所有节点的值均小于根节点的值
- 如果右子树不为空，则右子树上所有节点的值均大于根节点的值
- 左、右子树也都是二叉查找树
3. 分布均匀的**二叉查找树**，如果节点总数是n，则**搜索节点的时间复杂度就是O(logn)，和树的深度是一样
的**，这种**依靠比较大小来逐步查找**的方式，和二分查找算法非常相似

##### 2. 维持相对顺序
1. 二叉查找树要求左子树小于父节点，右子树大于父节点，正是这样保证了二叉树的有序性。
2. 二叉查找树又叫二叉排序树(binary sort tree)
3. **二叉树的自平衡**实现方式有：红黑树、AVL树、树堆等。
4. 二叉堆也维持着相对的顺序。不过二叉堆的条件要宽松一些，只要求父节点比它的左右孩子都大

## 2. 二叉树的遍历

### 2.1 遍历
1. 在计算机程序中，遍历本身是一个线性操作。
2. 而二叉树，是非线性数据结构，遍历时需要把非线性关联的节点转化成一个线性的序列，以不同的方式来遍历，遍历出的序列顺序也不同
3. 从节点之间位置关系的角度来看，二叉树的遍历分为4种
- 前序遍历(根左右)
- 中序遍历(左根右)
- 后序遍历(左右跟)
- 层序遍历
4. 或者分为两大类
- **深度优先遍历(前序、中序、后序遍历)**
- **广度优先遍历(层序遍历)**

### 2.2 深度优先遍历
1. 深度优先，偏向于纵深，“一头扎到底”的访
问方式。用**递归实现**方便
2. 前序遍历，输出顺序为(根左右)。
3. 中序遍历，输出顺序为(左根右)
4. 后序遍历，输出顺序为(左右跟)
5. 二叉树用**递归**方式来实现前序、中序、后序遍历，是最为自然的方式
6. **二叉树非递归遍历用栈实现，更方便一些。因为递归和栈都有回溯的特性**

### 2.3 广度优先遍历
1. **层序遍历**，顾名思义，就是二叉树按照从根节点到叶子节点的层次关系，一层一层横向遍历各个节点。
2. **用队列实现广度优先遍历**

## 3. 二叉堆

### 3.1 初识二叉堆
1. **二叉堆本质上是一种完全二叉树**，它分为两个类型：最大堆、最小堆。
2. **最大二叉堆**:任何一个父节点的值都大于或等于他左右孩子节点值。
3. **最小二叉堆**：任何一个父节点的值，都小于或等于他左右孩子节点的值。
4. **二叉堆的根节点叫作堆顶**。最大堆的堆顶是整个堆中的最大元素，最小堆的堆顶是整个堆中的最小元素。

### 3.2 二叉堆的自我调整
1. 通过二叉堆的**自我调整**来构建堆。**堆的自我调整，就是把一个不符合堆性质的完全二叉树，调整成一个堆**
2. 堆有如下操作:**插入节点、删除节点、构建二叉堆，这些操作都属于堆的自我调整。**
- **插入节点，插入的位置是完全二叉树的最后一个位置**，期间涉及节点的‘下沉’和‘上浮’，需满足二叉堆的特点， **时间复杂度O(logn)**
- **删除节点，删除的是处于堆顶的节点**。期间涉及节点的‘下沉’和‘上浮’，需满足二叉堆的特点，**O(logn)**
- **构建二叉堆，将一个无序的完全二叉树调整为二叉堆，本质就是让所有非叶子节点依次“下沉”**, **O(n)**

### 3.3 二叉堆的代码实现
1. 二叉堆虽然是完全二叉树，但存储方式并不是链式存储，而是顺序存储，即**二叉堆的所有节点都存储的数组中**。
2. 依靠数组下标来定位父节点的左、右孩子
3. 假设父节点的下标是parent，那么它的左孩子下标就是2×parent+1；右孩子下标就是2×parent+2。
4. **二叉堆是实现堆排序及优先队列的基础**

## 4. 优先队列
1. 优先队列不再遵循先入先出的原则，而是分两种情况
- **最大优先队列**，无论入队顺序如何，都是**当前最大**的元素优先出列
- **最小优先队列**，无论入队顺序如何，都是**当前最小**的元素优先出列
2. **用最大二叉堆来实现最大优先队列，每一次入队就是堆的插入操作，每一次出队就是删除堆顶的操作**
3. **二叉堆节点"上浮"和"下沉"的时间复杂度都是O(logn)，所以优先队列入队和出队的时间复杂度也是O(logn)。**

## 5. 小结
1. 树、二叉树、二叉树的遍历分为:深度优先遍历(前序、中序、后序遍历)和广度优先遍历(层序遍历)
2. 二叉堆，一种特殊的完全二叉树，底层使用数组实现的。分最大堆和最小堆。
3. 优先队列基于二叉堆实现的，不遵循先进先出的原则，分为最大优先队列和最小优先队列。

# 四、排序算法

## 1. 排序算法分类
1. 按时间复杂度的不同，大致分为3类
2. **O(n^2):** **冒泡、选择、插入、希尔**(O(nlogn<希尔< O(n^2))
3. **O(nlogn):快速、归并、堆排序**
4. **时间复杂度为线性的:计数、桶排序、基数**
5. 还可根据其稳定性分为:**稳定排序、不稳定排序**
6. 如果**值相同的元素在排序后仍然保持着排序前的顺序**，则这样的排序算法是**稳定排序**
7. 如果**值相同的元素在排序后打乱了排序前的顺序**，则这样的排序算法是**不稳定排序**。
![image](https://note.youdao.com/yws/res/28006/72C8A365C7BA423684DB6B9916F42F81)

## 2. 冒泡排序，O(n^2)

### 2.1 冒泡排序及优化
1. 冒泡排序，bubble sort，过程:**相邻的元素两两比较，当元素大于右侧相邻元素时，互换位置；当元素小于或等于右侧相邻元素时，位置不变。**第1轮结束时，最大的元素跑到了最后边**，每一轮都要遍历所有元素，总共遍历(元素数量-1)轮。**
2. **冒泡是一种稳定的排序**，值相等的元素并不会打乱原本的顺序，**平均时间复杂度是O(n^2)**
3. 第一版冒泡排序，使用双循环实现，外部循环控制所有的回合，内部循环实现每一轮的冒泡处理，先进行元素比较，再进行元素交换。
4. 冒泡排序的优化。
- 快到最后时，当数列已经有序时，最后剩余的几轮排序不必要执行了，当数列已经有序时，直接break跳出大循环。
- 数列有序区的界定，有可能大于第几轮的长度，每一轮排序后，记录下来最后一次元素交换的位置，该位置即为无序数列的边界，再往后就是有序区了。
![image](https://note.youdao.com/yws/res/28008/C2C53CC455294EA6AC08F72763FD602A)

### 2.2 鸡尾酒排序
1. 基于冒泡排序的一种升级排序法，鸡尾酒排序
2. 冒泡排序中每个元素向着数组一侧移动，从左到右进行着**单向的位置**交换。
3. 而鸡尾酒排序的**元素比较和交换过程是双向的**，排序过程就像钟摆一样，**第1轮从左
到右，第2轮从右到左，第3轮再从左到右**……
4. 鸡尾酒排序的优点是能够在特定条件下，减少排序的回合数；而缺点就是代码量几乎增加了一倍。
5. 至于它能发挥出优势的场景，是**大部分元素已经有序**的情况

## 3. 快速排序，O(n^2)

### 3.1 快排
1. 冒泡和快排一样，都属于**交换排序**，通过元素之间的比较和交换位置来达到排序的目的。不稳定排序。
2. 快排在每一轮挑选一个**基准元素**，比他大的元素放到右边，比他小的元素放到左边，从而把数列拆解成两部分。这种思路叫**分治法**。
3. 在分治法思想下，原数列每一轮都被拆分成两部分，直到不可再分为止。
4. 每一轮的比较和交换，需要把数组全部元素都遍历一遍，时间复杂度是O(n)，假如元素个数是n，那么平均情况下需要logn轮，因此快速排序算法总体的平均时间复杂度是**O(nlogn)**。

### 3.1 基准元素、元素的交换
1. 选择第一个元素为基准元素时，当假如**有一个逆序列**时，每轮排序，数列并没有被分成两部分，每一轮只是确定了基准元素的位置，**无法发挥分治的优**势，时间复杂度变成了O(n^2)
2. **虽然快速排序的平均时间复杂度是O(nlogn)，但最坏情况下的时间复杂度是O(n^2 )。**
3. 实现小于基准元素的都交换到左侧，大于基准元素的都交换到右侧。都用到了递归实现，方法有:
- **双边循环法**
- **单边循环法**
4. 双边循环法从数组的两边交替遍历元素,单边循环法则简单得多，只从数组的一边对元素进行遍历和交换，
5. 绝大多数的递归逻辑，都可以用栈的方式来代替，用非递归的方式，可以用栈来实现。
![image](https://note.youdao.com/yws/res/28010/FF5AA0E7F7124B899743728382D66BA0)

## 4. 堆排序
1. 二叉堆排序算法步骤:
- 把无序数组构建成二叉堆。需要从小到大排序，则构建成最大堆；需要从大到小排序，则构建成最小堆。
- 循环删除堆顶元素，替换到二叉堆的末尾，调整堆产生新的堆顶。
2. **堆排序的空间复杂度是O(1),不稳定排序。平均和最坏时间复杂度均为O(nlogn)。**

## 5. 计数排序和桶排序
1. 在理想情况下，某些算法可以做到**线性的时间复杂度**。
1. 冒泡、快排和堆排序都是基于**元素之间的比较**来排序的。
2. 有些特殊的排序不基于元素比较，如计数排序、桶排序、基数排序等。

### 5.1 计数排序
1. 计数排序是利用**数组下标**来确定元素的正确位置的。
2. **适用于一定范围内的整数排序，如果原始数列的规模是n,最大和最小整数的差值是m,时间复杂度是O(n+m)**，
3. 至于空间复杂度，如果不考虑结果数组，只考虑统计数组大小的话，空间复杂度是O(m)。
4. 计数排序的局限性:
- 当数列最大和最小值差距过大时，并不适合用计数排序。
- 当数列元素不是整数时，也不适合用计数排序。
5. 对于这些局限性，另一种线性时间排序算法做出了弥补，这种排序算法叫作**桶排序**

### 5.2 桶排序
1. 桶排序需创建若干个桶来协助排序，每一个桶代表一个区间范围，里面可以承载一个或多个元素。
2. 具体需要建立多少个桶，如何确定桶的区间范围，有很多种不同的方式。
3. 如：创建的桶数量等于原始数列的元素数量，区间跨度 = （最大值-最小值）/ （桶的数量 - 1）
4. 桶排序的总体时间复杂度为O(n)，空间复杂度也是O(n)。

## 6 排序算法对比

排序算法 | 平均时间复杂度 | 最坏时间复杂度 | 空间复杂度 | 是否稳定排序
---|---|---|---|---|
冒泡排序 | O(n^2) | O(n^2) | O(1) | 稳定
鸡尾酒排序 | O(n^2) | O(n^2) | O(1) | 稳定
快速排序 | O(nlogn) | O(n^2) | O(logn) | 不稳定
堆排序 | O(nlogn) | O(nlogn) | O(1) | 不稳定
计数排序 | O(n+m) | O(n+m) | O(m) | 稳定
桶排序 | O(n) | O(nlogn) | O(n) | 稳定

# 五、面试算法题
1. 
